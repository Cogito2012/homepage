<html>
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">	
	<title>Wentao Bao</title>
	<meta content="Wentao Bao, cogito2012.github.io/homepage" name="keywords">
	<link rel="stylesheet" href="./index_files/jemdoc.css" type="text/css">
	<script async="" src="http://www.google-analytics.com/analytics.js"></script>
	<script>
		(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
		(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
		m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
		})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
		ga('create', 'UA-66888300-1', 'auto');
		ga('send', 'pageview');
	</script>
	<script type="text/javascript" src="./index_files/jquery-1.12.4.min.js"></script>
	<style>
	a {color: #2471a3; text-decoration: none;}
	a:hover {color: #5499c7;}
	a.btn {background-color: #2471a3; color: #fff; font-size: 12px; margin-top: 4px; display: inline-block; padding: 0 4px; border-radius: 2px; line-height: 1.5em;}
	a.btn:hover {background-color: #174e74;}
	a.btn.btn-red {background-color: #d63a3a;}
	a.btn.btn-red:hover {background-color: #a02727;}
	a.btn.btn-orange {background-color: #e2700c;}
	a.btn.btn-orange:hover {background-color: #c46009;}
	a.btn.btn-dark {background-color: #345;}
	a.btn.btn-dark:hover {background-color: #234;}
	p {line-height: 1.5em;}
	.nobreak {white-space: nowrap;}
	.noselect {-webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none;}
	.bold {font-weight: bold;}
	.italic {font-style: italic;}
	.bulletpoints {line-height: 1.5em;}
	.row {box-sizing: border-box;}
	.row-media {display: block; float: left; width: 180px; height: 90px; background-position: center; background-size: contain; background-repeat: no-repeat; border-radius: 6px; border: 1px solid #def;}
	.row-text {display: block; float: left; margin-left: 16px; line-height: 1.5em; max-width: 662px;}
	.row-text span {line-height: inherit;}
	.clearfix {content: ""; clear: both; display: table;}
	.publication {margin-bottom: 32px; margin-left: 16px;}
	.press {width: 100px; height: 80px; border: 1px solid #def; margin-right: 12px; background-size: cover;}  
	.img-contain {background-size: contain !important;}
	.footer {background-color: #345; width: 100%}
	.footer-content {color: #fff; font-size: 10px; padding: 6px 0; max-width: 900px; margin: auto;}

	@media only screen and (max-width: 1150px) {
		.header-profile-picture, .header-text {display: block; margin: auto; text-align: center;}
		.header-profile-picture {margin-bottom: 12px; width: 140px; height: 140px;}
		body {font-size: 18px;}
		a.btn {font-size: 14px; padding: 2px 6px;}
	}

	@media only screen and (max-width: 900px) {
		.publication {margin-bottom: 46px;}
		.publication .row-media {width: 260px; height: 130px; margin: auto; margin-bottom: 12px; display: block;}
		.publication .row-text {display: block; width: 100%; margin-left: 0;}
		.press {display: block;}
	}
    </style>
</head>


<body>
<div id="layout-content" style="margin-top:25px">

<table cellpadding="11px">
	<tbody>
		<tr>
			<td width="720px">
				<div id="toptitle">
					<h1>Wentao BAO (包文韬) &nbsp; </h1>
				</div>
                <h3>Ph.D. Candidate</h3>       
				<p>
					<!-- <a href="https://www.egr.msu.edu/actionlab">ACTION Lab</a><br>  -->
					<a href="http://aiactionlab.com">ACTION Lab</a><br> 
					<a href="https://www.cse.msu.edu/">Department of Computer Science and Engineering</a><br>
					<a href="https://msu.edu/">Michigan State University</a><br>
					428 S. Shaw Lane, East Lansing, MI 48824, U.S.A<br>
					<br>
					Email:  wtbao2018 at gmail dot com<br>
					<br>
					<a href="./files/Wentao-Bao.pdf"> <img src="./files/logo-cv.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://github.com/Cogito2012"> <img src="./files/logo-github.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://www.zhihu.com/people/Cogito2012"> <img src="./files/logo-zhihu.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://scholar.google.com/citations?user=fBcEItYAAAAJ&hl=en"> <img src="./files/logo-googlescholar.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
					<a href="https://www.linkedin.com/in/wentao-bao-a59b88125"> <img src="./files/logo-linkin.png" height="30px" style="margin-bottom:-3px; margin-right: 10px"> </a>
                </p>
			</td>
			<td valign="middle">
				<img src="./files/roundhead3.png" border="0" width="180"><br><br>
			</td>
		</tr>
	</tbody>
</table>

<h2>About Me</h2>
	<p style="text-align:justify;">I am a final-year Ph.D. candidate (2019-) at the <a href="https://www.cse.msu.edu/">Department of Computer Science and Engineering (CSE)</a> of <a href="https://msu.edu/">Michigan State University (MSU)</a>, working with Prof. <a href="https://www.egr.msu.edu/~yukong/">Yu Kong</a>. Prior to MSU, I spent three Ph.D. years (2019-2022) at the <a href="https://www.rit.edu/computing/">B. Thomas Golisano College of Computing and Information Sciences (GCCIS)</a> of <a href="https://www.rit.edu/">Rochester Institute of Technology (R.I.T)</a>, working with Prof. <a href="https://www.egr.msu.edu/~yukong/">Yu Kong</a> and Prof. <a href="https://www.rit.edu/mining/qi-yu">Qi Yu</a>. I received my Master's degree (2016-2019) and Bachelor's degree (2012-2016) at the <a href="https://rsgis.whu.edu.cn/English/Home.htm">School of Remote Sensing and Information Engineering</a>, <a href="http://en.whu.edu.cn/"> Wuhan University (WHU)</a> where I was advised by<a href="https://www.researchgate.net/scientific-contributions/Daiqin-Yang-2059970064"> Prof. Daiqin Yang</a> and<a href="https://zhenzhong-chen.github.io"> Prof. Zhenzhong Chen</a> at the <a href="http://iip.whu.edu.cn">Lab. of Intelligent Information Processing
 (IIP)</a>. I have research internship collaborations with excellent industrial researchers from Apple, OPPO US Research Center, and NEC Lab America. 
	</p>
	<p style="text-align:justify;"><strong>I develop AI to understand the open visual world</strong>. To achieve this goal, I am broadly interested in using images/videos/text to solve real-world challenges including the visual recognition, prediction, understanding, and reasoning. My research works are related to <strong>open-set</strong>, <strong>video understanding</strong>, <strong>vision-language</strong> and <strong>3D vision</strong>. Recently, I am particularly interested in multi-modal LLM and generative AI for complex visual understanding and reasoning problems. Feel free to reach out to me if you are interested in collaboration.
	</p>

	<!-- <p style="text-align:justify;font-size:130%;"><font color="#E74C3C"><strong>I am open to research positions from academia and industry.</strong></font></p> -->


<h2>News [<img src="./index_files//update.gif">]</h2>
	<div  style="overflow-y: scroll; height:200px;">
	<table border="1" style="border-width: 0px;" width="1050">
	<tbody>
	<tr>
	<td style="border-style: none; border-width: medium;">
    <ul>
		<li type="circle">2024.03: I am honored to be selected to present in <a href="https://cvpr.thecvf.com/Conferences/2024/CallForDoctoralConsortium">CVPR 2024 Doctoral Consortium!</a></li>
		<li type="circle">2024.02: I successfuly passed the MSU PhD Comprehensive Exam, being a Ph.D. candidate!</li>
		<li type="circle">2023.07: One paper is accepted by <strong>ICCV 2023</strong>.</li>
    	<li type="circle">2023.05: I am invited to deliver a talk on open-set recognition at the the 2nd MSU-ND workshop.</li>
		<li type="circle">2023.02: I will be a research intern at <strong>NEC Laboratories America, Inc.</strong> (Princeton, NJ) in this summer.</li>
		<li type="circle">2023.02: One co-authored paper is accepted by <strong>CVPR 2023</strong>.</li>
    	<li type="circle">2022.08: I started my second journey of Ph.D. study at the CSE department at <strong>MSU</strong>!</li>
    	<li type="circle">2022.07: One co-authored paper is accepted by <strong>ECCV 2022</strong>.</li>
    	<li type="circle">2022.06: Start my internship at <strong>OPPO U.S. Research Center</strong> at Palo Alto, CA. (on-site)</li>
    	<li type="circle">2022.05: I attended the conference <strong>ICRA 2022</strong> on-site at Philadelphia, PA.</li>
    	<li type="circle">2022.04: I received the <strong>CVPR 2022 Travel Award</strong> to attend the conference at New Orleans, LA.</li>
		<li type="circle">2022.03: One paper is accepted by <strong>CVPR 2022</strong> for <strong>Oral</strong> presentation!</li>
    	<li type="circle">2021.10: One co-authored paper is accepted by <strong>BMVC 2021</strong>.</li>
    	<li type="circle">2021.07: Two papers are accepted by <strong>ICCV 2021</strong>, with one paper for <strong>Oral</strong> presentation!</li>
		<li type="circle">2021.06: Start my internship at <strong>Apple Inc.</strong>, 3D Vision Team at Apple Maps. (remote)</li>
		<li type="circle">2021.04: One co-authored paper is accepted by <strong>IJCNN 2021</strong>.</li>
		<li type="circle">2020.07: Two papers are accepted by <strong>ACM MM 2020</strong> (one co-authored).</li>
		<li type="circle">2020.07: One co-authored paper is accepted by <strong>ECCV 2020</strong>.</li>
		<li type="circle">2020.06: One paper is accepted by <strong>IROS 2020</strong>.</li>
		<li type="circle">2020.06: One co-authored paper is accepted by <strong>ICPR 2020</strong>.</li>
		<li type="circle">2020.05: I passed the <strong>Ph.D. Research Potential Assessment</strong>!</li>
		<li type="circle">2019.08: Start my new journey at <strong>RIT</strong>, Rochester, NY.</li>
    </ul><br>
    </td>
	</tr>
	</tbody>
	</table>
	</div>

<h2>Selected Publications</h2>
  <h3>Preprints</h3>
  
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_emola.png);"></div>
	<div class="row-text">
		Facial Affective Behavior Analysis with Instruction Tuning<br/>
		Yifan Li, Anh Dao, <span class="bold">Wentao Bao</span>, Zhen Tan, Tianlong Chen, Huan Liu, Yu Kong<br/>
	    <span class="italic">Preprint, 2024</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2404.05052.pdf">arXiv</a>
	  <a class="btn" href="bibs/emola.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_plid.png);"></div>
	<div class="row-text">
		Prompting Language-Informed Distribution for Compositional Zero-Shot Learning<br/>
		<span class="bold">Wentao Bao</span>, Lichang Chen, Heng Huang, Yu Kong<br/>
	    <span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2305.14428.pdf">arXiv</a>
	  <a class="btn" href="bibs/plid.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_fineosr.png);"></div>
	<div class="row-text">
		Latent Space Energy-based Model for Fine-grained Open Set Recognition<br/>
		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
	    <span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2309.10711.pdf">arXiv</a>
	  <a class="btn" href="bibs/fineosr.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/arxiv_gencnp.png);"></div>
	<div class="row-text">
		On Model Explanations with Transferable Neural Pathways<br/>
		Xinmiao Lin, <span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
		<span class="italic">Preprint, 2023</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2309.09887.pdf">arXiv</a>
	  <a class="btn" href="bibs/gencnp.txt">BibTeX</a>
	</div>
  </div>


  <h3>Conferences</h3>

  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/iccv23_usst.png);"></div>
	<div class="row-text">
		Uncertainty-aware State Space Transformer for Egocentric 3D Hand Trajectory Forecasting<br/>
		<span class="bold">Wentao Bao</span>, Lele Chen, Libing Zeng, Zhong Li, Yi Xu, Junsong Yuan, Yu Kong<br/>
		<span class="italic">International Conference on Computer Vision (<strong>ICCV</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2023/papers/Bao_Uncertainty-aware_State_Space_Transformer_for_Egocentric_3D_Hand_Trajectory_Forecasting_ICCV_2023_paper.pdf">PDF</a> 
		<a class="btn btn-orange" href="https://github.com/oppo-us-research/USST">Code</a>
		<a class="btn btn-orange" href="https://actionlab-cv.github.io/EgoHandTrajPred">Project</a>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2307.08243.pdf">arXiv</a>
	  <a class="btn" href="bibs/usst.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/cvpr23_face3d.png);"></div>
	<div class="row-text">
		3D-aware Facial Landmark Detection via Multiview Consistent Training on Synthetic Data<br/>
		Libing Zeng, Lele Chen, <span class="bold">Wentao Bao</span>, Zhong Li, Yi Xu, Junsong Yuan, Nima Khademi Kalantari<br/>
		<span class="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2023</span><br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2023/papers/Zeng_3D-Aware_Facial_Landmark_Detection_via_Multi-View_Consistent_Training_on_Synthetic_CVPR_2023_paper.pdf">PDF</a>
		<a class="btn btn-orange" href="https://github.com/libingzeng/landmark_consistent_plugin">Code</a>
		<a class="btn btn-orange" href="https://libingzeng.github.io/projects/landmark/landmark.html">Project</a>
	    <a class="btn" href="bibs/face3d.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/eccv22_openvad.png);"></div>
	<div class="row-text">
		Towards Open Set Video Anomaly Detection<br/>
		Yuansheng Zhu, <span class="bold">Wentao Bao</span>, Qi Yu<br/>
		<span class="italic">European Conference on Computer Vision (<strong>ECCV</strong>), 2022</span><br/>
	    <a class="btn btn-red" href="https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136940387.pdf">PDF</a>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2208.11113.pdf">arXiv</a>
		<a class="btn btn-orange" href="https://github.com/YUZ128pitt/Towards-OpenVAD">Code</a>
	    <a class="btn" href="bibs/openvad.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/cvpr22_opental.png);"></div>
	<div class="row-text">
		OpenTAL: Towards Open Set Temporal Action Localization<br/>
		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
		<span class="italic">IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2022</span> (<strong style="color: red;">Oral</strong>)<br/>
	    <a class="btn btn-red" href="https://openaccess.thecvf.com/content/CVPR2022/papers/Bao_OpenTAL_Towards_Open_Set_Temporal_Action_Localization_CVPR_2022_paper.pdf">PDF</a>
		<a class="btn btn-red" href="https://arxiv.org/pdf/2203.05114.pdf">arXiv</a>
		<a class="btn btn-red" href="files/posters/OpenTAL-poster.pdf">Poster</a>
	    <a class="btn btn-orange" href="https://github.com/Cogito2012/OpenTAL">Code</a>
	    <a class="btn" href="bibs/opental.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
  	<div class="row-media" style="background-image: url(files/pubs/bmvc21_fep.png);"></div>
  	<div class="row-text">
  		Gradient Frequency Modulation for Visually Explaining Video Understanding Models<br/>
  		Xinmiao Lin, <span class="bold">Wentao Bao</span>, Matthew Wright, Yu Kong<br/>
  		<span class="italic">British Machine Vision Conference (<strong>BMVC</strong>), 2021</span><br/>
  		<a class="btn btn-red" href="https://arxiv.org/abs/2111.01215">arXiv</a>
		<a class="btn btn-red" href="">PDF</a> 
		<!-- <a class="btn btn-orange" href="https://github.com/Cogito2012/DEAR">Code</a> -->
		<a class="btn" href="bibs/fep.txt">BibTeX</a>
  	</div>
  </div>
  <div class="publication row clearfix">
  	<div class="row-media" style="background-image: url(files/pubs/iccv21_dear.png);"></div>
  	<div class="row-text">
  		Evidential Deep Learning for Open Set Action Recognition<br/>
  		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
  		<span class="italic">International Conference on Computer Vision (<strong>ICCV</strong>), 2021</span> (<strong style="color: red;">Oral</strong>)<br/>
		<a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Bao_Evidential_Deep_Learning_for_Open_Set_Action_Recognition_ICCV_2021_paper.pdf">PDF</a> 
  		<a class="btn btn-red" href="https://arxiv.org/abs/2107.10161">arXiv</a>
  		<a class="btn btn-red" href="files/posters/DEAR-PosterPDF.pdf">Poster</a>
		<a class="btn btn-orange" href="https://github.com/Cogito2012/DEAR">Code</a>
		<a class="btn" href="bibs/dear.txt">BibTeX</a>
  	</div>
  </div>
  <div class="publication row clearfix">
  	<div class="row-media" style="background-image: url(files/pubs/iccv21_drive.png);"></div>
  	<div class="row-text">
  		DRIVE: Deep Reinforced Accident Anticipation with Visual Explanation<br/>
  		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
  		<span class="italic">International Conference on Computer Vision (<span class="bold">ICCV</span>), 2021</span><br/>
		<a class="btn btn-red" href="https://openaccess.thecvf.com/content/ICCV2021/papers/Bao_DRIVE_Deep_Reinforced_Accident_Anticipation_With_Visual_Explanation_ICCV_2021_paper.pdf">PDF</a> 
  		<a class="btn btn-red" href="https://arxiv.org/abs/2107.10189">arXiv</a>
  		<a class="btn btn-red" href="files/posters/DRIVE-PosterPDF.pdf">Poster</a>
		<a class="btn btn-orange" href="https://github.com/Cogito2012/DRIVE">Code</a>
		<a class="btn" href="bibs/drive.txt">BibTeX</a>
  	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/ijcnn21_anomaly.png);"></div>
	<div class="row-text">
		Multiple Instance Relational Learning for Video Anomaly Detection<br/>
		Xiwen Dengxiong, <span class="bold">Wentao Bao</span>, Yu Kong<br/>
		<span class="italic">International Joint Conference on Neural Network (<strong>IJCNN</strong>), 2021</span><br/>
		<!-- <a class="btn btn-red" href="">arXiv</a> -->
		<a class="btn btn-red" href="https://doi.org/10.1109/IJCNN52387.2021.9534124">DOI</a> 
		<!-- <a class="btn btn-orange" href="">Code</a> -->
		<a class="btn" href="bibs/anomaly.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/mm20_ustring.png);"></div>
	<div class="row-text">
		Uncertainty-based Traffic Accident Anticipation with Spatio-Temporal Relational Learning<br/>
		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
		<span class="italic">The 28th ACM International Conference on Multimedia (<strong>MM</strong>), 2020</span><br/>
		<a class="btn btn-red" href="https://arxiv.org/abs/2008.00334">arXiv</a> 
		<a class="btn btn-red" href="https://dl.acm.org/doi/10.1145/3394171.3413827">DOI</a> 
		<a class="btn btn-orange" href="https://github.com/Cogito2012/UString">Code</a> 
		<a class="btn btn-dark" href="https://github.com/Cogito2012/CarCrashDataset">Dataset</a> 
		<a class="btn" href="bibs/ustring.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/mm20_stgrounding.png);"></div>
	<div class="row-text">
		Activity-driven Weakly-Supervised Spatio-Temporal Grounding from Untrimmed Videos<br/>
		Junwen Chen, <span class="bold">Wentao Bao</span>, Yu Kong<br/>
		<span class="italic">The 28th ACM International Conference on Multimedia (<strong>MM</strong>), 2020</span><br/>
		<a class="btn btn-red" href="https://dl.acm.org/doi/abs/10.1145/3394171.3413614">DOI</a>
		<!-- <a class="btn btn-orange" href="">Code</a> -->
		<a class="btn" href="bibs/stgrounding.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/eccv20_activity.jpg);"></div>
	<div class="row-text">
		Group Activity Prediction with Sequential Relational Anticipation Model<br/>
		Junwen Chen, <span class="bold">Wentao Bao</span>, Yu Kong<br/>
		<span class="italic">European Conference on Computer Vision (<strong>ECCV</strong>), 2020</span><br/>
		<a class="btn btn-red" href="https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123660579.pdf">PDF</a>
		<a class="btn btn-red" href="https://arxiv.org/abs/2008.02441">arXiv</a>
		<a class="btn btn-orange" href="https://github.com/junwenchen/GAP_SRAM">Code</a>
		<a class="btn" href="bibs/group_activity.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/iros20_oacv.png);"></div>
	<div class="row-text">
		Object-Aware Centroid Voting for Monocular 3D Object Detection<br/>
		<span class="bold">Wentao Bao</span>, Qi Yu, Yu Kong<br/>
		<span class="italic">IEEE/RSJ International Conference on Intelligent Robots and Systems (<strong>IROS</strong>), 2020</span><br/>
		<a class="btn btn-red" href="http://ras.papercept.net/images/temp/IROS/files/2022.pdf">PDF</a> 
		<a class="btn btn-red" href="https://arxiv.org/abs/2007.09836">arXiv</a> 
		<a class="btn btn-orange" href="https://www.youtube.com/watch?v=i0ZZNuZGX-o">Demo</a>
		<a class="btn" href="bibs/oacv.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/icpr20_pampnn.png);"></div>
	<div class="row-text">
		Privacy Attributes-aware Message Passing Neural Network for Visual Privacy Attributes Classification<br/>
		Hanbin Hong, <span class="bold">Wentao Bao</span>, Yuan Hong, Yu Kong<br/>
		<span class="italic">International Conference on Pattern Recognition (<strong>ICPR</strong>), 2020</span><br/>
		<!-- <a class="btn btn-red" href="">arXiv</a> -->
		<a class="btn btn-red" href="https://doi.org/10.1109/ICPR48806.2021.9412853">DOI</a> 
		<a class="btn" href="bibs/pampnn.txt">BibTeX</a>
	</div>
  </div>
  
  <h3>Journals</h3>
  
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/neurocom20_dcsm.png);"></div>
	<div class="row-text">
		Human Scanpath Prediction based on Deep Convolutional Saccadic Model<br/>
		<span class="bold">Wentao Bao</span>, Zhenzhong Chen<br/>
		<span class="italic">Elsevier Journal of Neurocomputing (<strong>Neurocomputing</strong>), 2020</span><br/>
		<a class="btn btn-red" href="https://doi.org/10.1016/j.neucom.2020.03.060">DOI</a> 
		<!-- <a class="btn btn-orange" href="">Code</a> -->
		<a class="btn" href="bibs/dcsm.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/tip20_monofenet.png);"></div>
	<div class="row-text">
		MonoFENet: Monocular 3D Object Detection with Feature Enhancement Networks<br/>
		<span class="bold">Wentao Bao</span>, Bin Xu, Zhenzhong Chen<br/>
		<span class="italic">IEEE Transactions on Image Processing</i> (<strong>TIP</strong>), 2019</span><br/>
		<a class="btn btn-red" href="https://doi.org/10.1109/TIP.2019.2952201">DOI</a> 
		<!-- <a class="btn btn-orange" href="">Code</a> -->
		<a class="btn" href="bibs/monofenet.txt">BibTeX</a>
	</div>
  </div>
  <div class="publication row clearfix">
	<div class="row-media" style="background-image: url(files/pubs/grsl17_glbs.jpg);"></div>
	<div class="row-text">
		Group Lasso based Band Selection for Hyperspectral Image Classification<br/>
		Daiqin Yang, <span class="bold">Wentao Bao</span><br/>
		<span class="italic">IEEE Geoscience and Remote Sensing Letters</i> (<strong>GRSL</strong>), 2017</span><br/>
		<a class="btn btn-red" href="https://doi.org/10.1109/LGRS.2017.2768074">DOI</a> 
		<a class="btn btn-orange" href="https://github.com/Cogito2012/GLBS">Code</a>
		<a class="btn btn-dark" href="https://drive.google.com/drive/folders/1SOwxlY6RBkrKAFz2Xfb1SlaF07w2G_Fv">Dataset</a> 
		<a class="btn" href="bibs/glbs.txt">BibTeX</a>
	</div>
  </div>

<!--
  <h3>Patents</h3>
  <ul>
	<li type="disc">
    Jiangping Chen, <strong>Wentao Bao</strong>, Yaqi Liu. Self-adaption Indoor Parking Navigation and Automatic
Parking System and Method based on Bluetooth Low Energy (BLE), <strong>China Invention Patent (Authorized)</strong>,
Application No. CN201710791726.5, Publication No. CN107605219A, Publication Date Jan. 19th, 2018.
	</li>
  </ul>	
-->

<h2>Selected Awards & Honors</h2>
  <h3>Awards</h3>
    <ul>
	<li type="disc"> <strong>CVPR 2024 Travel Award</strong> for presentation in <a href="https://media.eventhosts.cc/Conferences/CVPR2024/CVPR_main_conf_2024.pdf"> CVPR'24 Doctoral Consortium</a>, Seattle, USA, 2024.</li>
    <li type="disc"> <strong>CVPR 2022 Travel Award</strong> for in-person conference at New Orleans, USA, 2022.
    <li type="disc"> <strong>AAAI 2020 Travel Award</strong> for in-person conference at New York, USA, 2020.
    <li type="disc"> <strong>Postgraduate Academic Innovation Award</strong> from Wuhan University, 2020. </li>
	<li type="disc"> <strong>Grand Prize Winner</strong>, ICME 2018 Grand Challenge on Salient360! Visual Attention Modeling for 360 Content, 2018. </li>
<!--<li type="disc"> <strong>Third-Class Prize</strong>, The 4th National Graduate Contest on Smart-City Technology and Creative Design, Abnormal Event Detection, 2017. </li> -->
	<li type="disc"> <strong>Bronze Award</strong> in Hubei Province, The 2nd China College Students "Internet Plus" Innovation and Entrepreneurship Competition. 2016. </li>
    <li type="disc"> <strong>Second-Class Prize</strong>, The 3rd National Graduate Contest on Smart-City Technology and Creative Design, Abnormal Event Detection. 2016. </li>
    <li type="disc"> <strong>First Prize</strong>, IEEE BigMM 2015 Challenge: "Large-Scale Object Tracking over a Multiple-Camera Network". 2015. </li>	
    <li type="disc"> <strong>Third-Class Prize</strong>, The 14th "Challenge Cup" National Undergraduate Curricular Academic Science and Technology Contest on "Smart City". 2015. </li>
<!--<li type="disc"> <strong>Third prize</strong>, The 13th "SuperMap Cup" National Undergraduate GIS Contest, Cloud Platform and Android Application Development. 2015. </li> -->
	<li type="disc"> <strong>Meritorious Winner</strong>, Mathematical Contest in Modeling (MCM). 2015. </li>
	<li type="disc"> <strong>Second prize</strong>, The 12th "SuperMap Cup" National Undergraduate GIS Contest, Android Application Development. 2014. </li>
	<br>
    </ul>

  <h3>Honors</h3>
	<ul>
	<li type="disc"> Excellent Graduated Student, Wuhan University, 2019. (top 5%)</li>
	<li type="disc"> China National Scholarship, 2018. </li>
    <li type="disc"> The First-class Academic Scholarship, Wuhan University, 2017 & 2018. (top 10%)</li>
	<li type="disc"> Outstanding Postgraduate Student, Wuhan University, 2017 & 2018. (top 10%)</li>
	<li type="disc"> Excellent Graduate Freshman Scholarship of Wuhan University, 2016. (top 10%)</li>
	<li type="disc"> Advanced Individual, Wuhan University, 2016. </li>
	</ul>	
	

<h2>Academic Services</h2>
  <h3>Conference Reviewer</h3>
    <ul>
    <li type="disc">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR): <a href="http://cvpr2021.thecvf.com">2021</a>, <a href="http://cvpr2022.thecvf.com">2022</a>, <a href="https://cvpr2023.thecvf.com">2023</a>, <a href="https://cvpr.thecvf.com/Conferences/2024">2024</a> </li>
    <li type="disc">IEEE/CVF International Conference on Computer Vision (ICCV): <a href="http://iccv2021.thecvf.com">2021</a></li>
    <li type="disc">European Conference on Computer Vision (ECCV): <a href="https://eccv2022.ecva.net">2022</a>, <a href="https://eccv.ecva.net/Conferences/2024">2024</a></li>
    <li type="disc">International Joint Conference on Artificial Intelligence (IJCAI): <a href="https://ijcai-23.org">2023</a></li>
	<li type="disc">ACM International Conference on Multimedia (ACM MM): <a href="https://2019.acmmm.org">2019</a>, <a href="https://2020.acmmm.org">2020</a>, <a href="https://2021.acmmm.org">2021</a>, <a href="https://2022.acmmm.org">2022</a>, <a href="https://2023.acmmm.org">2023</a></li>
    <li type="disc">IEEE/CVF Winter Conference on Applications of Computer Vision (WACV): <a href="https://wacv2023.thecvf.com">2023</a>, <a href="https://wacv2024.thecvf.com">2024</a></li>
	<li type="disc">IEEE International Conference on Multimedia and Expo (ICME): <a href="https://2024.ieeeicme.org">2024</a> </li>
    <li type="disc">IEEE International Conference on Robotics and Automation (ICRA): <a href="http://www.icra2021.org">2021</a></li>
    <li type="disc">IEEE International Conference on Web Services (ICWS): <a href="https://conferences.computer.org/icws/2021">2021</a></li>
    <li type="disc">IEEE International Conference on Multisensor Fusion and Integration for Intelligent Systems (MFI): <a href="https://mfi2020.org">2020</a></li>
	</ul>
  <h3>Journal Reviewer</h3>
    <ul>
    <li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=34">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83">IEEE Transactions on Image Processing (TIP)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6046">IEEE Transactions on Multimedia (TMM)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76">IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</a>. </li>
	<li type="disc"> <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=19">IEEE Transactions on Instrumentation and Measurement (TIM)</a>. </li>
	<li type="disc"> <a href="https://www.ieee-ras.org/publications/ra-l">IEEE Robotics and Automation Letters (RA-L)</a>. </li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/pattern-recognition">Elsevier: Pattern Recognition (PR)</a>. </li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/journal-of-visual-communication-and-image-representation">Elsevier: Journal of Visual Communication and Image Representation (JVCI)</a>. </li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/information-sciences">Elsevier: Information Sciences (IS)</a>.</li>
	<li type="disc"> <a href="https://www.journals.elsevier.com/measurement">Elsevier: Measurement</a>.</li>
	<li type="disc"> <a href="https://www.springer.com/journal/530/">Multimedia System Journal (MMSJ)</a>. </li>
	<li type="disc"> <a href="https://academic.oup.com/comjnl">The Computer Journal</a>. </li>
	</ul>
  <h3>Membership</h3>
	<ul>
	<li type="disc"> IEEE Student Member.</li>
	<li type="disc"> ACM Student Member.</li>
	</ul>
  <h3>Volunteer</h3>
	<ul>
	<li type="disc"> <a href="https://aaai.org/Conferences/AAAI-20/"> Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI-20)</a>, Feb. 7-12, 2020, New York, USA.</li>
	</ul>
  <h3>Teaching</h3>
	<ul>
		<li type="disc">Teaching Assistant, MSU CSE-402: Biometrics and Pattern Recognition, FS2023.</li>
		<li type="disc">Teaching Activities (<a href="./files/slides/IntroDRL.pdf">DRL Intro.</a>), RIT CSCI-631: Foundations of Computer Vision, SS2021 & SS2022.</li>
		<li type="disc">Teaching Activities (<a href="./files/slides/DEAR-Talk.pdf">EDL Intro.</a>), RIT CISC-849: PhD Seminar, FS2021.</li>
	</ul>
  <h3>Academic Talks</h3>
  	<ul>
  		<li type="disc">2023.05.13: Delivering a talk at <a href="https://hal.cse.msu.edu/workshop/2nd-msu-nd-workshop/">the 2nd MSU-ND Computer Vision and Biometrics Workshop</a>, introducing on Evidential Deep Learning for Open-Set Action Recognition</li>
  	</ul>
  	<ul>
  		<li type="disc">2021.08.20 & 2021.09.16: Delivering two academic talks in Chinese media <a href="https://www.bilibili.com/video/BV1Gq4y1D7At">Jishi</a> and <a href="https://www.bilibili.com/video/BV1DM4y1G7Nx">TechBeat</a>, introducing our recent ICCV Oral paper.</li>
  	</ul>
	<ul>
		<li type="disc">2020.11.17: Delivering an academic talk in the 2020 RIT Graduate Virtual Showcase: A Vision Into the Future.</li>
	</ul>
<hr>

<table cellpadding="0px">
	<tbody>
		<tr>
			<td width="720px">
			<div id="clustrmaps-widget"></div>
				<script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=7seMHMuQZlvELLsuK6wd30IX5cz7U58mGsA8iV8s6_o"></script></script>
				</script>
			<div class="jvectormap-tip"></div>
			</td>
			<td valign="top">
				<div style="clear:both;">
				<p align="right"><font size="2">Last Updated on June 14, 2024<br>
				Published with <a href="https://pages.github.com/">GitHub Pages</a></font></p>
				</div>
				<div style="clear: both;">
				<p align="right"><font size="5"><img src="./index_files//raccoon.gif"></font></p>
				</div>
			</td>
		</tr>
	</tbody>
</table>

</body>
</html>